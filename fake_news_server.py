# -*- coding: utf-8 -*-
"""fake_news_server.ipynb

Automatically generated by Colaboratory.


**Installing Dependencies**
"""

!python3 -m pip install flask flask-cors flask-ngrok sk-video

"""**Import necessary libraries**"""

import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.text import one_hot
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Bidirectional
from tensorflow.keras.layers import Dropout
import nltk
import re
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
import itertools

## Download stopwords from nltk
nltk.download('stopwords')

from google.colab import drive
drive.mount('/content/drive')

"""**Reading Dataset**"""

!unzip /content/drive/My\ Drive/fake-news.zip -d /content/dataset
!cp /content/drive/My\ Drive/out.csv /content/dataset
indian_df = pd.read_csv('/content/dataset/out.csv')
df = pd.read_csv('/content/dataset/train.csv')

df = pd.concat([df, indian_df], ignore_index=True)

## Get the Independent Features
X=df.drop('label',axis=1)

## Get the Dependent features
y=df['label']



messages=X.copy()
messages.reset_index(inplace=True)

## variable declarations

# Vocabulary size
voc_size=5000

sent_length=20

"""**Dataset Preprocessing**"""

def preprocess(messages):
  ## Stemming data using porter stemmer
  ps = PorterStemmer()
  corpus = []
  for i in range(0, len(messages)):
      review = re.sub('[^a-zA-Z]', ' ', messages[i])
      review = review.lower()
      review = review.split()
      
      review = [ps.stem(word) for word in review if not word in stopwords.words('english')]
      review = ' '.join(review)
      corpus.append(review)

  ## ONE HOT ENCODING
  onehot_repr=[one_hot(words,voc_size)for words in corpus] 

  ## EMBEDDING REPRESENTATION
  embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)
  return embedded_docs
vectorizer = CountVectorizer() 
vectorizer.fit(messages['title'])
embedded_docs = preprocess(messages['title'])

"""# **MODEL CREATION**
**LSTM Model Creation**
"""

def lstm_model():
  embedding_vector_features=40
  model=Sequential()
  model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))
  model.add(Dropout(0.3))
  model.add(LSTM(100))
  model.add(Dropout(0.3))
  model.add(Dense(1,activation='sigmoid'))
  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
  return model

"""**BiLSTM Model Creation**"""

def bilstm_model():
  embedding_vector_features=40
  model=Sequential()
  model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))
  model.add(Bidirectional(LSTM(100)))
  model.add(Dropout(0.3))
  model.add(Dense(1,activation='sigmoid'))
  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
  return model

"""**Logistic Regression Model**"""

def logistic_regression(X_train, y_train):
  pipe = Pipeline([('vect', CountVectorizer()),
                  ('tfidf', TfidfTransformer()),
                  ('model', LogisticRegression())])
  # Fitting the model
  model = pipe.fit(X_train, y_train)
  return model

"""**Decision Tree**"""

def decision_tree(X_train, y_train):
  pipe = Pipeline([('vect', CountVectorizer()),
                  ('tfidf', TfidfTransformer()),
                  ('model', DecisionTreeClassifier(criterion= 'entropy',
                                            max_depth = 20, 
                                            splitter='best', 
                                            random_state=42))])
  # Fitting the model
  model = pipe.fit(X_train, y_train)
  return model

"""**Random Forest**"""

def random_forest(X_train, y_train):
  pipe = Pipeline([('vect', CountVectorizer()),
                 ('tfidf', TfidfTransformer()),
                 ('model', RandomForestClassifier(n_estimators=50, criterion="entropy"))])
  model = pipe.fit(X_train, y_train)
  return model

"""**Multinomial Naive Bayes**"""

def multinomial_nb(X_train, y_train):
  classifier=MultinomialNB()
  classifier.fit(X_train, y_train)
  return classifier

"""**Passive Aggressive Classifier**"""

def passive_aggressive(X_train, y_train):
  linear_clf = PassiveAggressiveClassifier(max_iter=50)
  linear_clf.fit(X_train, y_train)
  return linear_clf

"""**Training Model**"""

def train_model(input, output, model, epochs = 20, batch_size = 64):
  X_final=np.array(input)
  y_final=np.array(output)
  X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)
  model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=epochs,batch_size=batch_size)
  return model

"""# **Server Setup**

**Model Initialisation**
"""

lstm = lstm_model()
bilstm = bilstm_model()

"""**Training**"""

lstm = train_model(embedded_docs, y, lstm)
bilstm = train_model(embedded_docs, y, bilstm)
logisticRegression = logistic_regression(messages['title'], y)
decisionTree = decision_tree(messages['title'], y)
randomForest = random_forest(messages['title'], y)
X_input = vectorizer.transform(messages['title']).toarray()
multinomialNb = multinomial_nb(X_input, y)
passiveAggressive = passive_aggressive(X_input, y)

"""**Server Creation**"""

## Importing Flask libraries

from flask_ngrok import run_with_ngrok
from flask import Flask
from flask import request
from time import sleep
from flask_cors import CORS, cross_origin
import json

app = Flask(__name__)

cors = CORS(app)
app.config['CORS_HEADERS'] = 'Content-Type'

run_with_ngrok(app)   ## starts ngrok when the app is run

## Routes

@app.route('/')
def home():
  return "<h1>Welcome to Fake News Server</h1>"

@app.route('/testUrl', methods=['POST'])
def testUrl():
  content = ""
  source = "unknown"
  algos = []
  for key in request.values.keys():
    obj = json.loads(key)
    content = obj["content"]
    if obj["source"]:
      source = obj["source"]
    algos = obj["algos"]
    break
  print(content, source, algos)
  return "2"

@app.route('/predictClass', methods=['POST'])
def getClass():
  content = ""
  source = "unknown"
  algos = []
  for key in request.values.keys():
    obj = json.loads(key)
    content = obj["content"]
    if obj["source"]:
      source = obj["source"]
    algos = obj["algos"]
    break
  expected_out = 0
  out = 0
  original_content = content
  print(original_content)
  content = preprocess([original_content])
  
  if 1 in algos:
    lstm_pred = lstm.predict_classes(content)
    out += (lstm_pred*2)
    expected_out += 2
  if 2 in algos:
    bilstm_pred = bilstm.predict_classes(content)
    out += (bilstm_pred*2)
    expected_out += 2
  if 3 in algos:
    logisticReg_pred = logisticRegression.predict([original_content])
    out += logisticReg_pred
    expected_out += 1
  if 4 in algos: 
    decisionTree_pred = decisionTree.predict([original_content])
    out += decisionTree_pred
    expected_out += 1
  if 5 in algos:
    randomForest_pred = randomForest.predict([original_content])
    out += (randomForest_pred*2)
    expected_out += 2
  content = vectorizer.transform([original_content]).toarray()
  if 6 in algos:
    multinomialNb_pred = multinomialNb.predict(content)
    out += multinomialNb_pred
    expected_out += 1
  if 7 in algos:
    passiveAggressive_pred = passiveAggressive.predict(content)
    out += passiveAggressive_pred
    expected_out += 1
  
  if source == "rp":
    out += 4
  if source == "news":
    out += 2
  if source == "social":
    out += 1
  
  expected_out += 4
  prediction = out/expected_out
  return str(prediction)

## Starting Server
app.run()
